{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Chronic Absenteeism Rate Prediction (CARP) Extract Transform and Load (ETL)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Import Python libraries for data manipulation"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport re"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Import IBM Watson Studio utility library, initialize product credentials and define function for downloading project files"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": "# function to retrieve project assets \ndef download(project_file_name,project=None):    \n    # get the file\n    print(\"Attempting to get file {}\".format(project_file_name))\n    _bytes = project.get_file(project_file_name).read()\n\n    print(\"Downloading...\")\n    \n    with open(project_file_name, 'wb') as f: \n        f.write(bytearray(_bytes))\n        print(\"Completed writing out file\")\n        \n    return 0"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Define functions and patterns for data quality assessment and cleansing"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": "def valid_number(x):\n    if x in [np.nan, np.inf, np.NINF]:\n        return False\n    if type(x) in [np.int, np.float]:\n        return True\n    try:\n        float(x)\n        return True\n    except ValueError:\n        return False\n\ndef assess(df):\n    return int(np.around(df.applymap(valid_number).all(1).to_frame().rename(columns={0:'valid'}).query('valid').shape[0]/df.shape[0] * 100))\n\nnot_num = re.compile('[^0-9\\.]')\none_not_num = re.compile('^[^0-9\\.]$')\n\ndef clean(df):\n    return df.replace(one_not_num,'0').replace(not_num,'').astype('float')\nvalid_number(np.inf)\n\n\ndef valid_pct(valid_list, df_name):\n    Pct_Valid = assess(eval(df_name))\n    valid_list.append(dict(DataFrame=df_name, Pct_Valid=Pct_Valid))\n    return Pct_Valid\n\nvalid_list = []"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Process chronic absenteeism rate data from California Department of Education"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Attempting to get file la_county_chronic_absenteeism_2017-2018.csv\nDownloading...\nCompleted writing out file\nValid Rows Before Cleansing: 84%\n\nabs_18 (initial):\n         Year    Percent  Count  Total  Tract_Nbr\nTract                                           \n221402  2018  10.526316     26    247     221402\n197300  2018   9.053498     22    243     197300\n134521  2018  10.631229     32    301     134521\n571300  2018  10.779817     94    872     571300\n572100  2018   7.142857     12    168     572100\n"
                },
                {
                    "data": {
                        "text/plain": "(2158, 5)"
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "abs_file_name = 'la_county_chronic_absenteeism_2017-2018.csv'\ndownload(abs_file_name,project)\nabs_df = pd.read_csv(abs_file_name,usecols=[3,4,5,7,13],names=['Year','Percent', 'Count', 'Tract','Total'])\nabs_18 = abs_df.query(\"Year == '2018'\").copy()\n\nabs_18.loc[:,'Tract']=abs_18.Tract.astype(str)\nabs_18['Tract_Nbr'] = abs_18.Tract.astype(int)\nabs_18.set_index('Tract',inplace=True)\nprint (f\"Valid Rows Before Cleansing: {valid_pct(valid_list,'abs_18')}%\")\n\nabs_18.dropna(inplace=True)\nabs_18.Percent=abs_18.Percent.astype(float)\nabs_18.Total=abs_18.Total.str.replace(one_not_num,'0').str.replace(not_num,'').astype('int64')\nabs_18.Count=abs_18.Count.str.replace(one_not_num,'0').str.replace(not_num,'').astype('int64')\nprint('\\nabs_18 (initial):\\n',abs_18.head())\nabs_18.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Prepare American Community Survey (ACS) 2013-2017 median income in last 12 months data"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Attempting to get file median_income_2017.csv\nDownloading...\nCompleted writing out file\nValid Rows Before Cleansing: 99%\n\ninc_17:\n         Income\nTract         \n400100  208393\n400200  147500\n400300   88173\n400400  102821\n400500   92375\n"
                },
                {
                    "data": {
                        "text/plain": "(7174, 1)"
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "inc_file_name = 'median_income_2017.csv'\ndownload(inc_file_name,project)\ninc_17 = pd.read_csv(inc_file_name,skiprows=2,header=None,usecols=[1,3],names=['Tract','Income'])\ninc_17.loc[:,'Tract']=inc_17.Tract.astype(str).str.slice(start=4)\ninc_17.set_index('Tract',inplace=True)\nprint (f\"Valid Rows Before Cleansing: {valid_pct(valid_list,'inc_17')}%\")\ninc_17.dropna(inplace=True)\ninc_17.drop_duplicates(inplace=True)\ninc_17.Income=inc_17.Income.str.replace(one_not_num,'0').str.replace(not_num,'').astype('int64')\nprint('\\ninc_17:\\n',inc_17.head())\ninc_17.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Prepare ACS 2013-2017 educational attainment data"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Attempting to get file educ_attainment_by_tract_2017.csv\nDownloading...\nCompleted writing out file\nValid Rows Before Cleansing: 99%\n\nedu_17:\n         Pct_HS  Pct_Bach\nTract                   \n101110    78.6      21.5\n101122    91.8      25.7\n101210    74.1      16.6\n101220    79.4      18.7\n101300    86.1      30.3\n"
                },
                {
                    "data": {
                        "text/plain": "(2306, 2)"
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "edu_file_name = 'educ_attainment_by_tract_2017.csv'\ndownload(edu_file_name,project)\nedu_17=pd.read_csv(edu_file_name,usecols=['GEO.id2','HC02_EST_VC17','HC02_EST_VC18'])\nedu_17.columns=['Tract', 'Pct_HS', 'Pct_Bach']\nedu_17.drop([0,1],inplace=True)\nedu_17.loc[:,'Tract']=edu_17.Tract.astype(str).str.slice(start=5)\nedu_17.set_index('Tract',inplace=True)\nprint (f\"Valid Rows Before Cleansing: {valid_pct(valid_list,'edu_17')}%\")\nedu_17=clean(edu_17)\nedu_17.drop_duplicates(inplace=True)\nprint('\\nedu_17:\\n',edu_17.head())\nedu_17.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Prepare ACS 2013-2017 English language mastery data "
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Attempting to get file english_mastery_by_tract_2017.csv\nDownloading...\nCompleted writing out file\nValid Rows Before Cleansing: 99%\n\neng_17:\n         Pct_Eng\nTract          \n101110     78.3\n101122     88.7\n101210     64.0\n101220     68.2\n101300     85.6\n"
                },
                {
                    "data": {
                        "text/plain": "(563, 1)"
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "eng_file_name = 'english_mastery_by_tract_2017.csv'\ndownload(eng_file_name,project)\neng_17=pd.read_csv(eng_file_name,usecols=[1,9],names=['Tract','Pct_Eng'])\neng_17.drop([0,1],inplace=True)\neng_17.loc[:,'Tract']=eng_17.Tract.astype(str).str.slice(start=4)\neng_17.set_index('Tract',inplace=True)\nprint (f\"Valid Rows Before Cleansing: {valid_pct(valid_list,'eng_17')}%\")\neng_17=eng_17.query(\"Pct_Eng !='-'\")\neng_17.drop_duplicates(inplace=True)\neng_17=clean(eng_17)\nprint('\\neng_17:\\n',eng_17.head())\neng_17.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Prepare ACS 2013-2017 race of householder data "
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Attempting to get file race_of_householder_by_tract_2017.csv\nDownloading...\nCompleted writing out file\nValid Rows Before Cleansing: 99%\n\nrace_17:\n         Pct_White  Pct_Black  Pct_Native  Pct_Asian  Pct_Pac_Isl  Pct_Other  \\\nTract                                                                         \n400100  78.149920   2.392344    0.000000  14.114833     0.000000   0.717703   \n400200  85.990338   0.966184    0.603865   8.937198     0.000000   0.000000   \n400300  73.270952  11.432059    0.000000  10.821806     0.325468   1.342555   \n400400  70.156775   5.879059    0.783875  15.733483     0.000000   2.351624   \n400500  60.676923  24.861538    0.000000   4.861538     0.000000   2.523077   \n\n        Pct_Mixed  \nTract              \n400100   4.625199  \n400200   3.502415  \n400300   2.807160  \n400400   5.095185  \n400500   7.076923  \n"
                },
                {
                    "data": {
                        "text/plain": "(7968, 7)"
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "race_file_name = 'race_of_householder_by_tract_2017.csv'\ndownload(race_file_name,project)\nrace_17=pd.read_csv(race_file_name,usecols=[0,3,5,7,9,11,13,15])\nrace_17.loc[:,'Tract']=race_17.Tract.astype(str)\nrace_17.set_index('Tract',inplace=True)\nprint (f\"Valid Rows Before Cleansing: {valid_pct(valid_list,'race_17')}%\")\nrace_17.dropna(inplace=True)\nrace_17.drop_duplicates(inplace=True)\nrace_17 = clean(race_17)\nprint('\\nrace_17:\\n',race_17.head())\nrace_17.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Prepare ACS 2013-2017 employment status data"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Attempting to get file employment_status_2017.csv\nDownloading...\nCompleted writing out file\nValid Rows Before Cleansing: 99%\n\nemp_17:\n         Pct_LF_Part  Pct_EP_Ratio  Pct_Unemp\nTract                                       \n101110         62.7          56.6        9.6\n101122         75.0          69.3        7.6\n101210         69.3          62.4        9.9\n101220         57.3          53.2        7.0\n101300         54.4          48.8       10.3\n"
                },
                {
                    "data": {
                        "text/plain": "(2346, 3)"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "emp_file_name = 'employment_status_2017.csv'\ndownload(emp_file_name,project)\nemp_17=pd.read_csv(emp_file_name)\nemp_17.loc[:,'Tract']=emp_17.Tract.astype(int).astype(str)\nemp_17.set_index('Tract',inplace=True)\nprint (f\"Valid Rows Before Cleansing: {valid_pct(valid_list,'emp_17')}%\")\nemp_17 = clean (emp_17)\nprint('\\nemp_17:\\n',emp_17.head())\nemp_17.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Prepare ACS 2013-2017 disability data"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Attempting to get file disability_2017.csv\nDownloading...\nCompleted writing out file\nValid Rows Before Cleansing: 98%\n\ndis_17:\n         Pct_Dis_0-18  Pct_Dis_19-64  Pct_Dis_65+\nTract                                           \n101110      3.364486       6.558533    45.034247\n101122      8.959538       8.068903    33.928571\n101210      3.129161      16.438021    50.762527\n101220      0.000000      11.739745    62.500000\n101300      8.395522       8.966245    44.405594\n"
                },
                {
                    "data": {
                        "text/plain": "(2348, 3)"
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "dis_file_name = 'disability_2017.csv'\ndownload(dis_file_name,project)\ndis_17=pd.read_csv(dis_file_name,dtype=str)\ndis_17.set_index('Tract',inplace=True)\nprint (f\"Valid Rows Before Cleansing: {valid_pct(valid_list,'dis_17')}%\")\ndis_17 = clean(dis_17)\nprint('\\ndis_17:\\n',dis_17.head())\ndis_17.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Prepare ACS 2013-2017 commute data"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Attempting to get file commute_2017.csv\nDownloading...\nCompleted writing out file\nValid Rows Before Cleansing: 99%\n\ncom_17:\n         Pct_Hour_Commute  Pct_Male_Hour_Commute  Pct_Female_Hour_Commute  \\\nTract                                                                      \n101110              20.0                   21.2                     18.6   \n101122              18.7                   18.5                     18.8   \n101210              11.7                    5.6                     19.2   \n101220               6.6                    4.3                      9.5   \n101300              15.5                    8.9                     20.9   \n\n        Avg_Min_Commute  Avg_Min_Male_Commute  Avg_Min_Female_Commute  \nTract                                                                  \n101110             36.4                  37.0                    35.6  \n101122             40.4                  40.2                    40.8  \n101210             29.0                  27.2                    31.2  \n101220             28.8                  28.3                    29.3  \n101300             32.9                  29.1                    35.9  \n"
                },
                {
                    "data": {
                        "text/plain": "(2346, 6)"
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "com_file_name = 'commute_2017.csv'\ndownload(com_file_name,project)\ncom_17=pd.read_csv(com_file_name,dtype=str)\ncom_17.set_index('Tract',inplace=True)\nprint (f\"Valid Rows Before Cleansing: {valid_pct(valid_list,'com_17')}%\")\ncom_17 = clean(com_17)\nprint('\\ncom_17:\\n',com_17.head())\ncom_17.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Prepare ACS 2013-2017 children's health insurance coverage data"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Attempting to get file health_insurance_2017.csv\nDownloading...\nCompleted writing out file\nValid Rows Before Cleansing: 100%\n\nins_17:\n         Pct_Male_Ins  Pct_Female_Ins\nTract                               \n400100         100.0      100.000000\n400200         100.0      100.000000\n400300         100.0       98.595506\n400400         100.0       81.987578\n400500         100.0       98.130841\n"
                },
                {
                    "data": {
                        "text/plain": "(8059, 2)"
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "ins_file_name = 'health_insurance_2017.csv'\ndownload(ins_file_name,project)\nins_17=pd.read_csv(ins_file_name,dtype=str)\nins_17.set_index('Tract',inplace=True)\nprint (f\"Valid Rows Before Cleansing: {valid_pct(valid_list,'ins_17')}%\")\nins_17 = clean(ins_17)\nprint('\\nins_17:\\n',ins_17.head())\nins_17.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Prepare ACS 2013-2017 marital status data"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Attempting to get file marital_status_2017.csv\nDownloading...\nCompleted writing out file\nValid Rows Before Cleansing: 99%\n\nmar_17:\n         Pct_Married  Pct_Widowed  Pct_Divorced  Pct_Separated  \\\nTract                                                           \n101110         46.9          6.0          11.5            1.2   \n101122         57.9          4.0           9.5            2.9   \n101210         43.7          4.4           8.2            4.4   \n101220         48.0          7.4           8.8            2.7   \n101300         51.5          6.8          10.3            0.1   \n\n        Pct_Never_Married  \nTract                      \n101110               34.5  \n101122               25.7  \n101210               39.2  \n101220               33.2  \n101300               31.2  \n"
                },
                {
                    "data": {
                        "text/plain": "(2346, 5)"
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "mar_file_name = 'marital_status_2017.csv'\ndownload(mar_file_name,project)\nmar_17=pd.read_csv(mar_file_name,dtype=str)\nmar_17.set_index('Tract',inplace=True)\nprint (f\"Valid Rows Before Cleansing: {valid_pct(valid_list,'mar_17')}%\")\nmar_17 = clean(mar_17)\nprint('\\nmar_17:\\n',mar_17.head())\nmar_17.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Prepare ACS 2013-2017 citizenship and nativity (birthplace) data"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Attempting to get file citizenship_nativity_2017.csv\nDownloading...\nCompleted writing out file\nValid Rows Before Cleansing: 100%\n\ncit_17:\n         Pct_US_Born_Citizen  Pct_US_Terr_Born_Citizen  \\\nTract                                                   \n101110            65.418309                  0.000000   \n101122            67.232376                  0.000000   \n101210            50.405428                  0.000000   \n101220            48.832335                  0.000000   \n101300            61.143524                  0.210035   \n\n        Pct_Foreign_Born_Citizen  Pct_Naturalized_Citizen  Pct_Non_Citizen  \nTract                                                                       \n101110                  1.905388                21.309680        11.366623  \n101122                  5.450392                24.477807         2.839426  \n101210                  1.390038                27.271223        20.933311  \n101220                  1.017964                31.766467        18.383234  \n101300                  1.470245                32.648775         4.527421  \n"
                },
                {
                    "data": {
                        "text/plain": "(2326, 5)"
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "cit_file_name = 'citizenship_nativity_2017.csv'\ndownload(cit_file_name,project)\ncit_17 = pd.read_csv(cit_file_name,dtype=str)\ncit_17.set_index('Tract',inplace=True)\nprint (f\"Valid Rows Before Cleansing: {valid_pct(valid_list,'cit_17')}%\")\ncit_17 = clean(cit_17)\nprint('\\ncit_17:\\n',cit_17.head())\ncit_17.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Prepare ACS 2013-2017 geographical mobility data"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Attempting to get file mobility_2017.csv\nDownloading...\nCompleted writing out file\nValid Rows Before Cleansing: 99%\n\nmob_17:\n         Pct_Moved_In_County  Pct_Moved_Diff_County  Pct_Moved_Diff_State  \\\nTract                                                                      \n101110                  2.6                    3.3                   0.7   \n101122                  4.5                    5.0                   0.0   \n101210                  3.7                    0.0                   0.0   \n101220                  5.4                    0.3                   0.5   \n101300                  4.7                    0.0                   0.8   \n\n        Pct_Moved_Intl  \nTract                   \n101110             0.0  \n101122             0.0  \n101210             0.0  \n101220             1.6  \n101300             0.0  \n"
                },
                {
                    "data": {
                        "text/plain": "(2346, 4)"
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "mob_file_name = 'mobility_2017.csv'\ndownload(mob_file_name,project)\nmob_17=pd.read_csv(mob_file_name,dtype=str)\nmob_17.set_index('Tract',inplace=True)\nprint (f\"Valid Rows Before Cleansing: {valid_pct(valid_list,'mob_17')}%\")\nmob_17 = clean(mob_17)\nprint('\\nmob_17:\\n',mob_17.head())\nmob_17.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Join all dataframes by census tract number"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {
                "scrolled": false
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "****Final Joined Dataset***\nTotal Rows:\t\t 2158\nValid Rows After Joins:\t 100%\n"
                },
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Percent</th>\n      <th>Count</th>\n      <th>Total</th>\n      <th>Tract_Nbr</th>\n      <th>Income</th>\n      <th>Pct_HS</th>\n      <th>Pct_Bach</th>\n      <th>Pct_Eng</th>\n      <th>Pct_White</th>\n      <th>...</th>\n      <th>Pct_Never_Married</th>\n      <th>Pct_US_Born_Citizen</th>\n      <th>Pct_US_Terr_Born_Citizen</th>\n      <th>Pct_Foreign_Born_Citizen</th>\n      <th>Pct_Naturalized_Citizen</th>\n      <th>Pct_Non_Citizen</th>\n      <th>Pct_Moved_In_County</th>\n      <th>Pct_Moved_Diff_County</th>\n      <th>Pct_Moved_Diff_State</th>\n      <th>Pct_Moved_Intl</th>\n    </tr>\n    <tr>\n      <th>Tract</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>101110</th>\n      <td>2018</td>\n      <td>11.076923</td>\n      <td>36</td>\n      <td>325</td>\n      <td>101110</td>\n      <td>51209.0</td>\n      <td>78.6</td>\n      <td>21.5</td>\n      <td>78.3</td>\n      <td>77.489177</td>\n      <td>...</td>\n      <td>34.5</td>\n      <td>65.418309</td>\n      <td>0.000000</td>\n      <td>1.905388</td>\n      <td>21.309680</td>\n      <td>11.366623</td>\n      <td>2.6</td>\n      <td>3.3</td>\n      <td>0.7</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>101122</th>\n      <td>2018</td>\n      <td>9.251102</td>\n      <td>21</td>\n      <td>227</td>\n      <td>101122</td>\n      <td>85460.0</td>\n      <td>91.8</td>\n      <td>25.7</td>\n      <td>88.7</td>\n      <td>86.359901</td>\n      <td>...</td>\n      <td>25.7</td>\n      <td>67.232376</td>\n      <td>0.000000</td>\n      <td>5.450392</td>\n      <td>24.477807</td>\n      <td>2.839426</td>\n      <td>4.5</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>101210</th>\n      <td>2018</td>\n      <td>11.466666</td>\n      <td>43</td>\n      <td>375</td>\n      <td>101210</td>\n      <td>34627.0</td>\n      <td>74.1</td>\n      <td>16.6</td>\n      <td>64.0</td>\n      <td>80.000000</td>\n      <td>...</td>\n      <td>39.2</td>\n      <td>50.405428</td>\n      <td>0.000000</td>\n      <td>1.390038</td>\n      <td>27.271223</td>\n      <td>20.933311</td>\n      <td>3.7</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>101220</th>\n      <td>2018</td>\n      <td>7.203390</td>\n      <td>17</td>\n      <td>236</td>\n      <td>101220</td>\n      <td>40273.0</td>\n      <td>79.4</td>\n      <td>18.7</td>\n      <td>68.2</td>\n      <td>66.348449</td>\n      <td>...</td>\n      <td>33.2</td>\n      <td>48.832335</td>\n      <td>0.000000</td>\n      <td>1.017964</td>\n      <td>31.766467</td>\n      <td>18.383234</td>\n      <td>5.4</td>\n      <td>0.3</td>\n      <td>0.5</td>\n      <td>1.6</td>\n    </tr>\n    <tr>\n      <th>101300</th>\n      <td>2018</td>\n      <td>7.453416</td>\n      <td>36</td>\n      <td>483</td>\n      <td>101300</td>\n      <td>81076.0</td>\n      <td>86.1</td>\n      <td>30.3</td>\n      <td>85.6</td>\n      <td>89.011748</td>\n      <td>...</td>\n      <td>31.2</td>\n      <td>61.143524</td>\n      <td>0.210035</td>\n      <td>1.470245</td>\n      <td>32.648775</td>\n      <td>4.527421</td>\n      <td>4.7</td>\n      <td>0.0</td>\n      <td>0.8</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 44 columns</p>\n</div>",
                        "text/plain": "        Year    Percent  Count  Total  Tract_Nbr   Income  Pct_HS  Pct_Bach  \\\nTract                                                                         \n101110  2018  11.076923     36    325     101110  51209.0    78.6      21.5   \n101122  2018   9.251102     21    227     101122  85460.0    91.8      25.7   \n101210  2018  11.466666     43    375     101210  34627.0    74.1      16.6   \n101220  2018   7.203390     17    236     101220  40273.0    79.4      18.7   \n101300  2018   7.453416     36    483     101300  81076.0    86.1      30.3   \n\n        Pct_Eng  Pct_White  ...  Pct_Never_Married  Pct_US_Born_Citizen  \\\nTract                       ...                                           \n101110     78.3  77.489177  ...               34.5            65.418309   \n101122     88.7  86.359901  ...               25.7            67.232376   \n101210     64.0  80.000000  ...               39.2            50.405428   \n101220     68.2  66.348449  ...               33.2            48.832335   \n101300     85.6  89.011748  ...               31.2            61.143524   \n\n        Pct_US_Terr_Born_Citizen  Pct_Foreign_Born_Citizen  \\\nTract                                                        \n101110                  0.000000                  1.905388   \n101122                  0.000000                  5.450392   \n101210                  0.000000                  1.390038   \n101220                  0.000000                  1.017964   \n101300                  0.210035                  1.470245   \n\n        Pct_Naturalized_Citizen  Pct_Non_Citizen  Pct_Moved_In_County  \\\nTract                                                                   \n101110                21.309680        11.366623                  2.6   \n101122                24.477807         2.839426                  4.5   \n101210                27.271223        20.933311                  3.7   \n101220                31.766467        18.383234                  5.4   \n101300                32.648775         4.527421                  4.7   \n\n        Pct_Moved_Diff_County  Pct_Moved_Diff_State  Pct_Moved_Intl  \nTract                                                                \n101110                    3.3                   0.7             0.0  \n101122                    5.0                   0.0             0.0  \n101210                    0.0                   0.0             0.0  \n101220                    0.3                   0.5             1.6  \n101300                    0.0                   0.8             0.0  \n\n[5 rows x 44 columns]"
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Combine all dataframes\nabs_18_joined=abs_18.copy()\nabs_18_joined=abs_18_joined.join(inc_17,how='left')\nabs_18_joined=abs_18_joined.join(edu_17,how='left')\nabs_18_joined=abs_18_joined.join(eng_17,how='left')\nabs_18_joined=abs_18_joined.join(race_17,how='left')\nabs_18_joined=abs_18_joined.join(emp_17,how='left')\nabs_18_joined=abs_18_joined.join(dis_17,how='left')\nabs_18_joined=abs_18_joined.join(com_17,how='left')\nabs_18_joined=abs_18_joined.join(ins_17,how='left')\nabs_18_joined=abs_18_joined.join(mar_17,how='left')\nabs_18_joined=abs_18_joined.join(cit_17,how='left')\nabs_18_joined=abs_18_joined.join(mob_17,how='left')\n\n# Eliminate duplicates\nabs_18_joined=abs_18_joined[(np.invert(abs_18_joined.index.duplicated(keep='last')))]\n\n# Fill nulls \n#abs_18_joined.fillna(abs_18_joined.mean(),inplace=True)\nabs_18_joined.interpolate(method='linear',inplace=True)\n\nprint('****Final Joined Dataset***')\nprint('Total Rows:\\t\\t',abs_18_joined.shape[0])\nprint (f\"Valid Rows After Joins:\\t {valid_pct(valid_list,'abs_18_joined')}%\")\nabs_18_joined.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Save joined dataframe to object storage as project asset"
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {
                "scrolled": false
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "{'file_name': 'la_county_2018_chronic_absence_rates_with_predictor_variables.csv',\n 'message': 'File saved to project storage.',\n 'bucket_name': 'iverpyspark-donotdelete-pr-ysp8udweullapt',\n 'asset_id': '202734ea-4107-4400-a948-b100c7ae3719'}"
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "joined_file_name = r'la_county_2018_chronic_absence_rates_with_predictor_variables.csv'\njoined_csv_data = abs_18_joined.to_csv()\nproject.save_data(joined_file_name, joined_csv_data, set_project_asset=True, overwrite=True)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Save data quality assessment results to object storage as project asset"
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "{'file_name': 'valid_pct.csv',\n 'message': 'File saved to project storage.',\n 'bucket_name': 'iverpyspark-donotdelete-pr-ysp8udweullapt',\n 'asset_id': '5ca27496-e907-4512-abdf-ad18e8900706'}"
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "valid_df = pd.DataFrame(valid_list)\nvalid_df\nvalid_pct_file_name = 'valid_pct.csv'\nvalid_pct_csv_data = valid_df.to_csv(index=False)\nproject.save_data(valid_pct_file_name, valid_pct_csv_data, set_project_asset=True, overwrite=True)"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}