{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Chronic Absenteeism Rate Prediction (CARP) Deep Neural Network (DNN) Modeling"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Make preparations specific to IBM Watson Studio:  import and configure project utilities, define function to download project assets"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": "# function to retrieve project assets \ndef download(project_file_name,project=None):    \n    # get the file\n    print(\"Attempting to get file {}\".format(project_file_name))\n    _bytes = project.get_file(project_file_name).read()\n    \n    # download the file\n    print(\"Downloading...\")\n    \n    with open(project_file_name, 'wb') as f: \n        f.write(bytearray(_bytes))\n        print(\"Completed writing out file\")\n        \n    return 0"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Import required modules"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "Using TensorFlow backend.\n"
                }
            ],
            "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport re\nimport pickle\n\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold, ShuffleSplit\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Download datasets and recreate data created with CARP-ETL notebook"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Attempting to get file la_county_2018_chronic_absence_rates_with_predictor_variables.csv\nDownloading...\nCompleted writing out file\nAttempting to get file ranked_correlates.csv\nDownloading...\nCompleted writing out file\n\n***Prepared Data***\n        Year    Percent  Count  Total  Tract_Nbr   Income  Pct_HS  Pct_Bach  Pct_Eng  Pct_White  Pct_Black  Pct_Native  Pct_Asian  Pct_Pac_Isl  Pct_Other  Pct_Mixed  Pct_LF_Part  Pct_EP_Ratio  Pct_Unemp  Pct_Dis_0-18  \\\nTract                                                                                                                                                                                                                      \n101110  2018  11.076923     36    325     101110  51209.0    78.6      21.5     78.3  77.489177   2.040816    0.000000   4.761905          0.0  12.059369   3.648732         62.7          56.6        9.6      3.364486   \n101122  2018   9.251102     21    227     101122  85460.0    91.8      25.7     88.7  86.359901   0.000000    0.986031   8.052588          0.0   3.779786   0.821693         75.0          69.3        7.6      8.959538   \n101210  2018  11.466666     43    375     101210  34627.0    74.1      16.6     64.0  80.000000   2.961373    0.000000   3.090129          0.0  13.004292   0.944206         69.3          62.4        9.9      3.129161   \n101220  2018   7.203390     17    236     101220  40273.0    79.4      18.7     68.2  66.348449   1.670644    0.000000  14.240255          0.0  11.137629   6.603023         57.3          53.2        7.0      0.000000   \n101300  2018   7.453416     36    483     101300  81076.0    86.1      30.3     85.6  89.011748   1.313062    0.000000   5.805114          0.0   2.695232   1.174845         54.4          48.8       10.3      8.395522   \n\n        Pct_Dis_19-64  Pct_Dis_65+  Pct_Hour_Commute  Pct_Male_Hour_Commute  Pct_Female_Hour_Commute  Avg_Min_Commute  Avg_Min_Male_Commute  Avg_Min_Female_Commute  Pct_Male_Ins  Pct_Female_Ins  Pct_Married  \\\nTract                                                                                                                                                                                                            \n101110       6.558533    45.034247              20.0                   21.2                     18.6             36.4                  37.0                    35.6     94.376528       87.234043         46.9   \n101122       8.068903    33.928571              18.7                   18.5                     18.8             40.4                  40.2                    40.8    100.000000       84.513274         57.9   \n101210      16.438021    50.762527              11.7                    5.6                     19.2             29.0                  27.2                    31.2    100.000000       96.624473         43.7   \n101220      11.739745    62.500000               6.6                    4.3                      9.5             28.8                  28.3                    29.3     89.430894      100.000000         48.0   \n101300       8.966245    44.405594              15.5                    8.9                     20.9             32.9                  29.1                    35.9    100.000000      100.000000         51.5   \n\n        Pct_Widowed  Pct_Divorced  Pct_Separated  Pct_Never_Married  Pct_US_Born_Citizen  Pct_US_Terr_Born_Citizen  Pct_Foreign_Born_Citizen  Pct_Naturalized_Citizen  Pct_Non_Citizen  Pct_Moved_In_County  \\\nTract                                                                                                                                                                                                         \n101110          6.0          11.5            1.2               34.5            65.418309                  0.000000                  1.905388                21.309680        11.366623                  2.6   \n101122          4.0           9.5            2.9               25.7            67.232376                  0.000000                  5.450392                24.477807         2.839426                  4.5   \n101210          4.4           8.2            4.4               39.2            50.405428                  0.000000                  1.390038                27.271223        20.933311                  3.7   \n101220          7.4           8.8            2.7               33.2            48.832335                  0.000000                  1.017964                31.766467        18.383234                  5.4   \n101300          6.8          10.3            0.1               31.2            61.143524                  0.210035                  1.470245                32.648775         4.527421                  4.7   \n\n        Pct_Moved_Diff_County  Pct_Moved_Diff_State  Pct_Moved_Intl  \nTract                                                                \n101110                    3.3                   0.7             0.0  \n101122                    5.0                   0.0             0.0  \n101210                    0.0                   0.0             0.0  \n101220                    0.3                   0.5             1.6  \n101300                    0.0                   0.8             0.0  \n\n***Top Correlates***\n     Correlate\n0    Pct_Black\n1     Pct_Bach\n2       Income\n3       Pct_HS\n4  Pct_Married\n"
                }
            ],
            "source": "abs_file_name = 'la_county_2018_chronic_absence_rates_with_predictor_variables.csv'\ndownload(abs_file_name,project)\nabs_18 = pd.read_csv(abs_file_name, index_col='Tract')\nnp.set_printoptions(linewidth=250)\nranked_corr_file_name = 'ranked_correlates.csv'\ndownload(ranked_corr_file_name,project)\nranked_corr = pd.read_csv(ranked_corr_file_name,header=None,names=['Correlate'])\npd.set_option('display.max_columns', 50)\npd.set_option('display.width', 220)\nprint('\\n***Prepared Data***')\nprint(abs_18.head())\nprint('\\n***Top Correlates***')\nprint(ranked_corr.head())"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Define and run deep learning model"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "scrolled": false
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\nIteration 1:\n\nWARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/40\n1726/1726 [==============================] - 2s 1ms/step - loss: 1.9080\nEpoch 2/40\n1726/1726 [==============================] - 2s 937us/step - loss: 0.8802\nEpoch 3/40\n1726/1726 [==============================] - 2s 975us/step - loss: 0.8344\nEpoch 4/40\n1726/1726 [==============================] - 2s 936us/step - loss: 0.8057\nEpoch 5/40\n1726/1726 [==============================] - 2s 942us/step - loss: 0.8091\nEpoch 6/40\n1726/1726 [==============================] - 2s 923us/step - loss: 0.7797\nEpoch 7/40\n1726/1726 [==============================] - 2s 926us/step - loss: 0.7600\nEpoch 8/40\n1726/1726 [==============================] - 2s 940us/step - loss: 0.7690\nEpoch 9/40\n1726/1726 [==============================] - 2s 960us/step - loss: 0.7352\nEpoch 10/40\n1726/1726 [==============================] - 2s 905us/step - loss: 0.7753\nEpoch 11/40\n1726/1726 [==============================] - 2s 913us/step - loss: 0.7137\nEpoch 12/40\n1726/1726 [==============================] - 2s 926us/step - loss: 0.7106\nEpoch 13/40\n1726/1726 [==============================] - 2s 962us/step - loss: 0.7044\nEpoch 14/40\n1726/1726 [==============================] - 2s 942us/step - loss: 0.7108\nEpoch 15/40\n1726/1726 [==============================] - 2s 957us/step - loss: 0.6478\nEpoch 16/40\n1726/1726 [==============================] - 2s 961us/step - loss: 0.6076\nEpoch 17/40\n1726/1726 [==============================] - 2s 927us/step - loss: 0.6456\nEpoch 18/40\n1726/1726 [==============================] - 2s 950us/step - loss: 0.6069\nEpoch 19/40\n1726/1726 [==============================] - 2s 929us/step - loss: 0.5808\nEpoch 20/40\n1726/1726 [==============================] - 2s 937us/step - loss: 0.6075\nEpoch 21/40\n1726/1726 [==============================] - 2s 947us/step - loss: 0.5829\nEpoch 22/40\n1726/1726 [==============================] - 2s 940us/step - loss: 0.5697\nEpoch 23/40\n1726/1726 [==============================] - 2s 972us/step - loss: 0.5576\nEpoch 24/40\n1726/1726 [==============================] - 2s 905us/step - loss: 0.5413\nEpoch 25/40\n1726/1726 [==============================] - 2s 936us/step - loss: 0.5469\nEpoch 26/40\n1726/1726 [==============================] - 2s 929us/step - loss: 0.5543\nEpoch 27/40\n1726/1726 [==============================] - 2s 937us/step - loss: 0.5439\nEpoch 28/40\n1726/1726 [==============================] - 2s 962us/step - loss: 0.5520\nEpoch 29/40\n1726/1726 [==============================] - 2s 925us/step - loss: 0.5334\nEpoch 30/40\n1726/1726 [==============================] - 2s 927us/step - loss: 0.5492\nEpoch 31/40\n1726/1726 [==============================] - 2s 938us/step - loss: 0.5510\nEpoch 32/40\n1726/1726 [==============================] - 2s 936us/step - loss: 0.5280\nEpoch 33/40\n1726/1726 [==============================] - 2s 919us/step - loss: 0.5248\nEpoch 34/40\n1726/1726 [==============================] - 2s 923us/step - loss: 0.5437\nEpoch 35/40\n1726/1726 [==============================] - 2s 937us/step - loss: 0.5411\nEpoch 36/40\n1726/1726 [==============================] - 2s 928us/step - loss: 0.5324\nEpoch 37/40\n1726/1726 [==============================] - 2s 932us/step - loss: 0.5284\nEpoch 38/40\n1726/1726 [==============================] - 2s 938us/step - loss: 0.5214\nEpoch 39/40\n1726/1726 [==============================] - 2s 946us/step - loss: 0.5284\nEpoch 40/40\n1726/1726 [==============================] - 2s 971us/step - loss: 0.5255\n1726/1726 [==============================] - 1s 472us/step\n432/432 [==============================] - 0s 519us/step\nTrain r2 Score: 0.49725528115137596 Test r2 Score: 0.4502929174522652\n\nIteration 2:\n\nEpoch 1/40\n1726/1726 [==============================] - 2s 1ms/step - loss: 1.2029\nEpoch 2/40\n1726/1726 [==============================] - 2s 934us/step - loss: 0.9843\nEpoch 3/40\n1726/1726 [==============================] - 2s 961us/step - loss: 0.9845\nEpoch 4/40\n1726/1726 [==============================] - 2s 930us/step - loss: 0.9844\nEpoch 5/40\n1726/1726 [==============================] - 2s 946us/step - loss: 0.9839\nEpoch 6/40\n1726/1726 [==============================] - 2s 941us/step - loss: 0.9837\nEpoch 7/40\n1726/1726 [==============================] - 2s 962us/step - loss: 0.9845\nEpoch 8/40\n1726/1726 [==============================] - 2s 918us/step - loss: 0.9835\nEpoch 9/40\n1726/1726 [==============================] - 2s 918us/step - loss: 0.9837\nEpoch 10/40\n1726/1726 [==============================] - 2s 983us/step - loss: 0.9841\nEpoch 11/40\n1726/1726 [==============================] - ETA: 0s - loss: 0.987 - 2s 930us/step - loss: 0.9839\nEpoch 00011: early stopping\nEpoch 1/40\n1726/1726 [==============================] - 2s 1ms/step - loss: 1.0084\nEpoch 2/40\n1726/1726 [==============================] - 2s 940us/step - loss: 0.9836\nEpoch 3/40\n1726/1726 [==============================] - 2s 936us/step - loss: 0.9847\nEpoch 4/40\n1726/1726 [==============================] - 2s 984us/step - loss: 0.9848\nEpoch 5/40\n1726/1726 [==============================] - 2s 942us/step - loss: 0.9844\nEpoch 6/40\n1726/1726 [==============================] - 2s 957us/step - loss: 0.9841\nEpoch 7/40\n1726/1726 [==============================] - 2s 952us/step - loss: 0.9841\nEpoch 00007: early stopping\nEpoch 1/40\n1726/1726 [==============================] - 2s 1ms/step - loss: 1.0296\nEpoch 2/40\n1726/1726 [==============================] - 2s 960us/step - loss: 0.8550\nEpoch 3/40\n1726/1726 [==============================] - 2s 941us/step - loss: 0.8237\nEpoch 4/40\n1726/1726 [==============================] - 2s 936us/step - loss: 0.7995\nEpoch 5/40\n1726/1726 [==============================] - 2s 972us/step - loss: 0.7591\nEpoch 6/40\n1726/1726 [==============================] - 2s 953us/step - loss: 0.7393\nEpoch 7/40\n1726/1726 [==============================] - 2s 958us/step - loss: 0.7197\nEpoch 8/40\n1726/1726 [==============================] - 2s 940us/step - loss: 0.7183\nEpoch 9/40\n1726/1726 [==============================] - 2s 951us/step - loss: 0.7009\nEpoch 10/40\n1726/1726 [==============================] - 2s 935us/step - loss: 0.6738\nEpoch 11/40\n1726/1726 [==============================] - 2s 961us/step - loss: 0.6208\nEpoch 12/40\n1726/1726 [==============================] - 2s 964us/step - loss: 0.6351\nEpoch 13/40\n1726/1726 [==============================] - 2s 976us/step - loss: 0.6820\nEpoch 14/40\n1726/1726 [==============================] - 2s 954us/step - loss: 0.5797\nEpoch 15/40\n1726/1726 [==============================] - 2s 939us/step - loss: 0.6306\nEpoch 16/40\n1726/1726 [==============================] - 2s 950us/step - loss: 0.6205\nEpoch 17/40\n1726/1726 [==============================] - 2s 950us/step - loss: 0.6007\nEpoch 18/40\n1726/1726 [==============================] - 2s 964us/step - loss: 0.6008\nEpoch 19/40\n1726/1726 [==============================] - 2s 924us/step - loss: 0.5675\nEpoch 20/40\n1726/1726 [==============================] - 2s 963us/step - loss: 0.5751\nEpoch 21/40\n1726/1726 [==============================] - 2s 949us/step - loss: 0.5902\nEpoch 22/40\n1726/1726 [==============================] - 2s 938us/step - loss: 0.5597\nEpoch 23/40\n1726/1726 [==============================] - 2s 950us/step - loss: 0.5584\nEpoch 24/40\n1726/1726 [==============================] - 2s 926us/step - loss: 0.5408\nEpoch 25/40\n1726/1726 [==============================] - 2s 960us/step - loss: 0.5419\nEpoch 26/40\n1726/1726 [==============================] - 2s 961us/step - loss: 0.5679\nEpoch 27/40\n1726/1726 [==============================] - 2s 962us/step - loss: 0.5260\nEpoch 28/40\n1726/1726 [==============================] - 2s 961us/step - loss: 0.5380\nEpoch 29/40\n1726/1726 [==============================] - 2s 950us/step - loss: 0.5384\nEpoch 30/40\n1726/1726 [==============================] - 2s 932us/step - loss: 0.5286\nEpoch 31/40\n1726/1726 [==============================] - 2s 964us/step - loss: 0.5364\nEpoch 32/40\n1726/1726 [==============================] - 2s 973us/step - loss: 0.5432\nEpoch 00032: early stopping\n1726/1726 [==============================] - 1s 507us/step\n432/432 [==============================] - 0s 468us/step\nTrain r2 Score: 0.41230729577314196 Test r2 Score: 0.4469903169623737\n\nIteration 3:\n\nEpoch 1/40\n1726/1726 [==============================] - 2s 1ms/step - loss: 0.9985\nEpoch 2/40\n1726/1726 [==============================] - 2s 932us/step - loss: 0.9529\nEpoch 3/40\n1726/1726 [==============================] - 2s 957us/step - loss: 0.8393\nEpoch 4/40\n1726/1726 [==============================] - 2s 961us/step - loss: 0.7953\nEpoch 5/40\n1726/1726 [==============================] - 2s 937us/step - loss: 0.7929\nEpoch 6/40\n1726/1726 [==============================] - 2s 929us/step - loss: 0.7457\nEpoch 7/40\n1726/1726 [==============================] - 2s 949us/step - loss: 0.6979\nEpoch 8/40\n1726/1726 [==============================] - 2s 936us/step - loss: 0.7115\nEpoch 9/40\n1726/1726 [==============================] - 2s 939us/step - loss: 0.8168\nEpoch 10/40\n1726/1726 [==============================] - 2s 974us/step - loss: 0.7481\nEpoch 11/40\n1726/1726 [==============================] - 2s 949us/step - loss: 0.7208\nEpoch 12/40\n1726/1726 [==============================] - 2s 932us/step - loss: 0.6604\nEpoch 13/40\n1726/1726 [==============================] - 2s 943us/step - loss: 0.6972\nEpoch 14/40\n1726/1726 [==============================] - 2s 892us/step - loss: 0.6481\nEpoch 15/40\n1726/1726 [==============================] - 2s 910us/step - loss: 0.6515\nEpoch 16/40\n1726/1726 [==============================] - 2s 961us/step - loss: 0.6365\nEpoch 17/40\n1726/1726 [==============================] - 2s 944us/step - loss: 0.6423\nEpoch 18/40\n1726/1726 [==============================] - 2s 929us/step - loss: 0.6540\nEpoch 19/40\n1726/1726 [==============================] - 2s 941us/step - loss: 0.6617\nEpoch 20/40\n1726/1726 [==============================] - 2s 981us/step - loss: 0.6514\nEpoch 21/40\n1726/1726 [==============================] - 2s 927us/step - loss: 0.6358\nEpoch 22/40\n1726/1726 [==============================] - 2s 951us/step - loss: 0.6137\nEpoch 23/40\n1726/1726 [==============================] - 2s 960us/step - loss: 0.6106\nEpoch 24/40\n1726/1726 [==============================] - 2s 938us/step - loss: 0.6219\nEpoch 25/40\n1726/1726 [==============================] - 2s 921us/step - loss: 0.6011\nEpoch 26/40\n1726/1726 [==============================] - 2s 935us/step - loss: 0.6177\nEpoch 27/40\n1726/1726 [==============================] - 2s 959us/step - loss: 0.6173\nEpoch 28/40\n1726/1726 [==============================] - 2s 929us/step - loss: 0.6029\nEpoch 29/40\n1726/1726 [==============================] - 2s 960us/step - loss: 0.5961\nEpoch 30/40\n1726/1726 [==============================] - 2s 904us/step - loss: 0.6063\nEpoch 31/40\n1726/1726 [==============================] - 2s 949us/step - loss: 0.6002\nEpoch 32/40\n1726/1726 [==============================] - 2s 949us/step - loss: 0.6316\nEpoch 33/40\n1726/1726 [==============================] - 2s 938us/step - loss: 0.5908\nEpoch 34/40\n1726/1726 [==============================] - 2s 929us/step - loss: 0.5806\nEpoch 35/40\n1726/1726 [==============================] - 2s 961us/step - loss: 0.5862\nEpoch 36/40\n1726/1726 [==============================] - 2s 928us/step - loss: 0.5786\nEpoch 37/40\n1726/1726 [==============================] - 2s 925us/step - loss: 0.5864\nEpoch 38/40\n1726/1726 [==============================] - 2s 939us/step - loss: 0.5768\nEpoch 39/40\n1726/1726 [==============================] - 2s 937us/step - loss: 0.5839\nEpoch 40/40\n1726/1726 [==============================] - 2s 954us/step - loss: 0.5758\n1726/1726 [==============================] - 1s 471us/step\n432/432 [==============================] - 0s 453us/step\nTrain r2 Score: 0.43274694331856933 Test r2 Score: 0.45718519053418494\n\nIteration 4:\n\nEpoch 1/40\n1726/1726 [==============================] - 2s 1ms/step - loss: 1.0864\nEpoch 2/40\n1726/1726 [==============================] - 2s 946us/step - loss: 0.9855\nEpoch 3/40\n1726/1726 [==============================] - 2s 923us/step - loss: 0.9854\nEpoch 4/40\n1726/1726 [==============================] - 2s 964us/step - loss: 0.9855\nEpoch 5/40\n1726/1726 [==============================] - 2s 960us/step - loss: 0.9856\nEpoch 6/40\n1726/1726 [==============================] - 2s 951us/step - loss: 0.9856\nEpoch 7/40\n1726/1726 [==============================] - 2s 970us/step - loss: 0.9852\nEpoch 00007: early stopping\nEpoch 1/40\n1726/1726 [==============================] - 2s 1ms/step - loss: 1.1638\nEpoch 2/40\n1726/1726 [==============================] - 2s 938us/step - loss: 0.9493\nEpoch 3/40\n1726/1726 [==============================] - 2s 930us/step - loss: 0.8057\nEpoch 4/40\n1726/1726 [==============================] - 2s 960us/step - loss: 0.7909\nEpoch 5/40\n1726/1726 [==============================] - 2s 972us/step - loss: 0.8341\nEpoch 6/40\n1726/1726 [==============================] - 2s 953us/step - loss: 0.8018\nEpoch 7/40\n1726/1726 [==============================] - 2s 942us/step - loss: 0.7288\nEpoch 8/40\n1726/1726 [==============================] - 2s 981us/step - loss: 0.7919\nEpoch 9/40\n1726/1726 [==============================] - 2s 941us/step - loss: 0.7192\nEpoch 10/40\n1726/1726 [==============================] - 2s 949us/step - loss: 0.7021\nEpoch 11/40\n1726/1726 [==============================] - 2s 930us/step - loss: 0.6935\nEpoch 12/40\n1726/1726 [==============================] - 2s 973us/step - loss: 0.6819\nEpoch 13/40\n1726/1726 [==============================] - 2s 949us/step - loss: 0.6842\nEpoch 14/40\n1726/1726 [==============================] - 2s 944us/step - loss: 0.6436\nEpoch 15/40\n1726/1726 [==============================] - 2s 956us/step - loss: 0.6448\nEpoch 16/40\n1726/1726 [==============================] - 2s 948us/step - loss: 0.6302\nEpoch 17/40\n1726/1726 [==============================] - 2s 961us/step - loss: 0.6389\nEpoch 18/40\n1726/1726 [==============================] - 2s 963us/step - loss: 0.6060\nEpoch 19/40\n1726/1726 [==============================] - 2s 949us/step - loss: 0.5919\nEpoch 20/40\n1726/1726 [==============================] - 2s 948us/step - loss: 0.5821\nEpoch 21/40\n1726/1726 [==============================] - 2s 953us/step - loss: 0.6066\nEpoch 22/40\n1726/1726 [==============================] - 2s 926us/step - loss: 0.5654\nEpoch 23/40\n1726/1726 [==============================] - 2s 970us/step - loss: 0.5800\nEpoch 24/40\n1726/1726 [==============================] - 2s 951us/step - loss: 0.5673\nEpoch 25/40\n1726/1726 [==============================] - 2s 949us/step - loss: 0.5738\nEpoch 26/40\n1726/1726 [==============================] - 2s 941us/step - loss: 0.5476\nEpoch 27/40\n1726/1726 [==============================] - 2s 948us/step - loss: 0.5443\nEpoch 28/40\n1726/1726 [==============================] - 2s 949us/step - loss: 0.5326\nEpoch 29/40\n1726/1726 [==============================] - 2s 949us/step - loss: 0.5354\nEpoch 30/40\n1726/1726 [==============================] - 2s 964us/step - loss: 0.5567\nEpoch 31/40\n1726/1726 [==============================] - 2s 971us/step - loss: 0.5336\nEpoch 32/40\n1726/1726 [==============================] - 2s 937us/step - loss: 0.5283\nEpoch 33/40\n1726/1726 [==============================] - 2s 927us/step - loss: 0.5306\nEpoch 34/40\n1726/1726 [==============================] - 2s 938us/step - loss: 0.5334\nEpoch 35/40\n1726/1726 [==============================] - 2s 962us/step - loss: 0.5407\nEpoch 36/40\n1726/1726 [==============================] - 2s 949us/step - loss: 0.5190\nEpoch 37/40\n1726/1726 [==============================] - 2s 951us/step - loss: 0.5210\nEpoch 38/40\n1726/1726 [==============================] - 2s 948us/step - loss: 0.5253\nEpoch 39/40\n1726/1726 [==============================] - 2s 938us/step - loss: 0.5093\nEpoch 40/40\n1726/1726 [==============================] - 2s 943us/step - loss: 0.5143\n1726/1726 [==============================] - 1s 514us/step\n432/432 [==============================] - 0s 460us/step\nTrain r2 Score: 0.47172923115578314 Test r2 Score: 0.5008706116181166\n\nIteration 5:\n\nEpoch 1/40\n1726/1726 [==============================] - 2s 1ms/step - loss: 1.1602\nEpoch 2/40\n1726/1726 [==============================] - 2s 986us/step - loss: 0.8846\nEpoch 3/40\n1726/1726 [==============================] - 2s 959us/step - loss: 0.8325\nEpoch 4/40\n1726/1726 [==============================] - 2s 926us/step - loss: 0.8176\nEpoch 5/40\n1726/1726 [==============================] - 2s 951us/step - loss: 0.7450\nEpoch 6/40\n1726/1726 [==============================] - 2s 976us/step - loss: 0.7322\nEpoch 7/40\n1726/1726 [==============================] - 2s 969us/step - loss: 0.7406\nEpoch 8/40\n1726/1726 [==============================] - 2s 974us/step - loss: 0.7325\nEpoch 9/40\n1726/1726 [==============================] - 2s 949us/step - loss: 0.7127\nEpoch 10/40\n1726/1726 [==============================] - 2s 957us/step - loss: 0.7086\nEpoch 11/40\n1726/1726 [==============================] - 2s 978us/step - loss: 0.7017\nEpoch 12/40\n1726/1726 [==============================] - 2s 941us/step - loss: 0.6167\nEpoch 13/40\n1726/1726 [==============================] - 2s 959us/step - loss: 0.6282\nEpoch 14/40\n1726/1726 [==============================] - 2s 982us/step - loss: 0.6061\nEpoch 15/40\n1726/1726 [==============================] - 2s 950us/step - loss: 0.6059\nEpoch 16/40\n1726/1726 [==============================] - 2s 939us/step - loss: 0.6038\nEpoch 17/40\n1726/1726 [==============================] - 2s 950us/step - loss: 0.6051\nEpoch 18/40\n1726/1726 [==============================] - 2s 950us/step - loss: 0.5765\nEpoch 19/40\n1726/1726 [==============================] - 2s 948us/step - loss: 0.5778\nEpoch 20/40\n1726/1726 [==============================] - 2s 974us/step - loss: 0.6091\nEpoch 21/40\n1726/1726 [==============================] - 2s 950us/step - loss: 0.5587\nEpoch 22/40\n1726/1726 [==============================] - 2s 948us/step - loss: 0.5619\nEpoch 23/40\n1726/1726 [==============================] - 2s 950us/step - loss: 0.5702\nEpoch 24/40\n1726/1726 [==============================] - 2s 947us/step - loss: 0.5805\nEpoch 25/40\n1726/1726 [==============================] - 2s 968us/step - loss: 0.5792\nEpoch 26/40\n1726/1726 [==============================] - 2s 971us/step - loss: 0.5522\nEpoch 27/40\n1726/1726 [==============================] - 2s 972us/step - loss: 0.5573\nEpoch 28/40\n1726/1726 [==============================] - 2s 961us/step - loss: 0.5449\nEpoch 29/40\n1726/1726 [==============================] - 2s 950us/step - loss: 0.5764\nEpoch 30/40\n1726/1726 [==============================] - 2s 936us/step - loss: 0.5368\nEpoch 31/40\n1726/1726 [==============================] - 2s 963us/step - loss: 0.5535\nEpoch 32/40\n1726/1726 [==============================] - 2s 949us/step - loss: 0.5369\nEpoch 33/40\n1726/1726 [==============================] - 2s 963us/step - loss: 0.5395\nEpoch 34/40\n1726/1726 [==============================] - 2s 964us/step - loss: 0.5556\nEpoch 35/40\n1726/1726 [==============================] - 2s 936us/step - loss: 0.5427\nEpoch 00035: early stopping\n1726/1726 [==============================] - 1s 533us/step\n432/432 [==============================] - 0s 463us/step\nTrain r2 Score: 0.488928293118853 Test r2 Score: 0.4697908635658661\n"
                }
            ],
            "source": "# Define deep neural network\ninput_dim = 25 # define how many of the ranked correlates to use as predictor varFiables\nki='normal'\n\ndef nn_model(layer_1_dim=input_dim):\n    model = Sequential()\n    model.add(Dense(layer_1_dim, input_dim=layer_1_dim, kernel_initializer=ki, activation='relu'))\n    layer_2_dim = (layer_1_dim // 3) * 2 + 1\n    model.add(Dense(layer_2_dim,kernel_initializer=ki, activation='relu'))\n    layer_3_dim = (layer_2_dim // 3) * 2 + 1\n    model.add(Dense(layer_3_dim,kernel_initializer=ki, activation='relu'))\n    model.add(Dense(1, kernel_initializer=ki))\n    adam = Adam(lr=0.01, decay=0.001)\n    model.compile(loss='mean_squared_error', optimizer=adam)\n    return model\n\n# Select variables most highly correlated with target for model fitting -- this eliminates some noise\nvariables = list(ranked_corr[:input_dim]['Correlate'].values)\n\n\n# Define predictor and target while capturing mean and standard deviation to reinflate scaled data\n\nX = abs_18[variables]\nX_mean,X_std = X.mean(),X.std()\ny = abs_18['Percent']\ny_mean,y_std = y.mean(),y.std()\n\nscaler = StandardScaler(copy=True, with_mean=True, with_std=True)\nX_scaler = scaler.fit(X)\ny_scaler = scaler.fit(y.values.reshape(-1, 1))\n\nX_scaled = X_scaler.transform(X)\n\ny_scaled = y_scaler.transform(y.values.reshape(-1, 1))\n\n# Set parameters for iterative model fitting and prediction\n\ntarget_iterations = 5\nmax_epochs=40\nmin_epochs=25\nmax_loss = .62\n\n# Initialize accumulators for run\ncompleted_epochs = -1\ncompleted_iterations = 0\n\n# Define lists to accumulate the results of each iteration\n\ntrain_scores=[]\ntest_scores=[]\nX_tests=[]\ny_tests=[]\ny_test_preds=[]\n\n\n# Define estimator\n\nearly_stop = EarlyStopping(monitor='loss', min_delta=0.0005, patience=5, verbose=1, mode='min')\n\nestimator = KerasRegressor(build_fn=nn_model, epochs=max_epochs, batch_size=12, verbose=1, callbacks=[early_stop])\n\n# Iterate model fitting and prediction specified number of times while capturing results for model evaluation\n\nfor iteration in range (target_iterations):\n    \n    iteration += 1\n    print(f'\\nIteration {iteration}:\\n')\n    \n    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, shuffle=True, random_state=iteration)\n\n    # re-fit estimator until minimum epochs are completed without early stopping\n    in_progress = True\n    while in_progress:\n        nn_history = estimator.fit(X_train,y_train)\n        completed_epochs = len(nn_history.history['loss'])\n        loss = nn_history.history['loss'][-1]\n        if completed_epochs >= max_epochs or (completed_epochs >= min_epochs and loss <= max_loss):\n            in_progress = False\n\n    y_train_pred=estimator.predict(X_train)\n    y_test_pred=estimator.predict(X_test)\n\n    train_score = metrics.r2_score(y_train,y_train_pred)\n    test_score = metrics.r2_score(y_test,y_test_pred)\n    print('Train r2 Score:', train_score,'Test r2 Score:', test_score)\n        \n    X_tests.append(X_test)\n    y_tests.append(y_test)\n    y_test_preds.append(y_test_pred)\n    train_scores.append(train_score)\n    test_scores.append(test_score)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Save modeling results as project assets for evaluation by CARP-EVAL notebook"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "{'file_name': 'nn_results.p',\n 'message': 'File saved to project storage.',\n 'bucket_name': 'iverpyspark-donotdelete-pr-ysp8udweullapt',\n 'asset_id': '0d1bd654-82cf-4396-b581-753af5458440'}"
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "\nnn_results_file_name = 'nn_results.p'\nnn_results=dict(X_mean=X_mean, X_std=X_std, X_tests=X_scaler.inverse_transform(X_tests), y_tests=y_scaler.inverse_transform(y_tests),\n                y_test_preds=y_scaler.inverse_transform(y_test_preds), train_scores=train_scores, test_scores=test_scores)\npickled_nn_results = pickle.dumps(nn_results)\nproject.save_data(nn_results_file_name, pickled_nn_results, set_project_asset=True, overwrite=True)"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}